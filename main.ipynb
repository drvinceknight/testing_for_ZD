{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sym\n",
    "import axelrod as axl\n",
    "import axelrod.interaction_utils as iu\n",
    "\n",
    "import testzd as zd\n",
    "\n",
    "C, D = axl.Action.C, axl.Action.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = imp.load_source('parameters', 'data/raw/parameters.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extortionate zero determinant.\n",
    "\n",
    "In [1], given a match between 2 memory one strategies the concept of Zero Determinant strategies is introduced. It was showed that a player $p\\in\\mathbb{R}^4$ against a player $q\\in\\mathbb{R}^4$ could force a linear relationship between the scores.\n",
    "\n",
    "Assuming the following:\n",
    "\n",
    "- The utilities for player $p$: $S_x = (R, S, T, P)$ and for player $q$: $S_y = (R, T, S, P)$.\n",
    "- The normalised long run score for player $p$: $s_x$ and for player $q$: $s_y$.\n",
    "- Given $p=(p_1, p_2, p_3, p_4)$ a transformed (but equivalent) vector: $\\tilde p=(p_1 - 1, p_2 - 1, p_3, p_4)$, similarly: $\\tilde q=(1 - q_1, 1 - q_2, q_3, q_4)$\n",
    "\n",
    "The main result of [1] is that:\n",
    "\n",
    "if $\\tilde p = \\alpha S_x + \\beta S_y + \\gamma 1$ **or** if $\\tilde q = \\alpha S_x + \\beta S_y + \\gamma 1$ then:\n",
    "\n",
    "$$\n",
    "\\alpha s_x + \\beta s_y + \\gamma 1 = 0\n",
    "$$\n",
    "\n",
    "where $\\alpha, \\beta, \\gamma \\in \\mathbb{R}$\n",
    "\n",
    "As an example consider the `extort-2` strategy defined in [2]. This is given by:\n",
    "\n",
    "$$p=(8/9, 1/2, 1/3, 0)$$\n",
    "\n",
    "Let us use the `Axelrod` library [4, 5] to simulate some matches, here it is against some of the best strategies in the Axelrod library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.998"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extort2 = axl.ZDExtort2()\n",
    "players = (extort2, axl.EvolvedFSM16())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "scores = match.final_score_per_turn()\n",
    "np.round((scores[0] - 1) / (scores[1] - 1), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = (extort2, axl.EvolvedANN5())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "scores = match.final_score_per_turn()\n",
    "np.round((scores[0] - 1) / (scores[1] - 1), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.051"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = (extort2, axl.PSOGamblerMem1())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "scores = match.final_score_per_turn()\n",
    "np.round((scores[0] - 1) / (scores[1] - 1), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = (extort2, extort2)\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "scores = match.final_score_per_turn()\n",
    "(scores[0] - 1) / (scores[1] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `extort2` beats all these strategies but gets a low score against itself.\n",
    "\n",
    "In [1], in fact a specific type of Zero determinant strategy is considered, indeed if: $\\gamma=-(\\alpha + \\beta)P$ then the relationship $\\chi = S_X / S_Y$ holds where $\\chi = \\frac{-\\beta}{\\alpha}$ so that the $S_X - P$ will be at $\\chi$ times bigger than $S_Y - P$ as long as $\\chi > 1$. We can obtain a simple linear equation and an inequality that checks if a strategy is of this form:\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array([8 / 9, 1 / 2, 1 / 3, 0])\n",
    "zd.is_ZD(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.889, 0.5  , 0.333, 0.   ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(p, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note however that even if there is a slight measurement error then these equations will fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "approximate_p = p + 10 ** -5 * np.random.random(4)\n",
    "np.round(np.max(np.abs(p - approximate_p)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zd.is_ZD(approximate_p),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, this work proposes a statistical approach for recognising extortionate behaviour. This uses a least squares minimisation approach for the underlying linear algebraic problem being solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, SSError = zd.compute_least_squares(approximate_p)\n",
    "alpha, beta = x\n",
    "chi = -beta / alpha\n",
    "np.round(chi, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in the case of an approximation of `extort2` we recover the value of $\\chi=2$ (to the fifth decimal place).\n",
    "\n",
    "The value that is in fact being minised is called: $\\text{SSError}$. This in fact gives us a measure of how far from being an extortionate strategy a given strategy vector $p$ is.\n",
    "\n",
    "While all strategies are not necessarily memory one: so do not necessarily have a representation as a 4 dimensional vector. There transition rates from all states to any action can still be measured.\n",
    "\n",
    "Let us see how this works, using the 3 strategies above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_from_interactions(interactions):\n",
    "    vectors = []\n",
    "    for state_counter in iu.compute_state_to_action_distribution(interactions):\n",
    "        p = []\n",
    "        for state in ((C, C), (C, D), (D, C), (D, D)):\n",
    "            try:\n",
    "                p.append(state_counter[(state, C)] / (state_counter[(state, C)]  + state_counter[(state, D)] ) )\n",
    "            except ZeroDivisionError:\n",
    "                p.append(np.NaN)\n",
    "        vectors.append(p)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = (extort2, axl.EvolvedFSM16())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "p = get_p_from_interactions(interactions=interactions)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.375, 0.472, 0.544, 0.517])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(p, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how close this strategy is to being extortionate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.215"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, SSError = zd.compute_least_squares(p)\n",
    "np.round(SSError, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = (extort2, axl.EvolvedANN5())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "p = get_p_from_interactions(interactions=interactions)[1]\n",
    "x, SSError = zd.compute_least_squares(p)\n",
    "SSError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This strategy in fact does not visit all states so it is not possible to give a valid calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, nan, 0.8, 0.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.175"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = (extort2, axl.PSOGambler2_2_2())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "p = get_p_from_interactions(interactions=interactions)[1]\n",
    "x, SSError = zd.compute_least_squares(p)\n",
    "np.round(SSError, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that the `PSOGambler2_2_2` is \"more\" extortionate than the other two. Note: it is certainly not an extortionate strategy as $p_4 > 0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.105, 0.518, 0.002, 0.505])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(p, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually classify all potential extortionate strategies which is Figure 1 of the paper.\n",
    "\n",
    "The paper extends this work to consider a LARGE number of strategies, and identifies if and when strategies actually exhibit extortionate behaviour.\n",
    "\n",
    "We note that the strategies that exhibit strong evolutionary fitness are ones that are able to adapt their behaviour: they do not extort strong strategies (thus cooperation evolves) but they do extort weaker ones. For example, here is a list of strategies against which `EvolvedFSM16` is close to being ZD ($\\text{SSError} < 0.05$) and is close to being extortionate: ($p_4 < 0.05$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs AntiCycler, chi=-5.25, (S_X - 1)/(S_Y - 1)=-4.02\n",
      "vs Arrogant QLearner, chi=-12.09, (S_X - 1)/(S_Y - 1)=-6.24\n",
      "vs Bush Mosteller: 0.5, 0.5, 3.0, 0.5, chi=-2.79, (S_X - 1)/(S_Y - 1)=-5.75\n",
      "vs Cautious QLearner, chi=-12.09, (S_X - 1)/(S_Y - 1)=-6.24\n",
      "vs Colbert, chi=-8.44, (S_X - 1)/(S_Y - 1)=-4.15\n",
      "vs Hesitant QLearner, chi=-12.09, (S_X - 1)/(S_Y - 1)=-6.24\n",
      "vs Knowledgeable Worse and Worse, chi=-11.62, (S_X - 1)/(S_Y - 1)=-5.97\n",
      "vs Prober 4, chi=-47.75, (S_X - 1)/(S_Y - 1)=1.25\n",
      "vs Random: 0.5, chi=-3.02, (S_X - 1)/(S_Y - 1)=-4.29\n",
      "vs Risky QLearner, chi=-12.09, (S_X - 1)/(S_Y - 1)=-6.24\n",
      "vs Stochastic Cooperator, chi=-4.2, (S_X - 1)/(S_Y - 1)=-6.12\n",
      "vs ThueMorseInverse, chi=-5.25, (S_X - 1)/(S_Y - 1)=-4.04\n",
      "vs Tranquilizer, chi=9.25, (S_X - 1)/(S_Y - 1)=1.57\n",
      "vs Tullock: 11, chi=3.11, (S_X - 1)/(S_Y - 1)=0.52\n",
      "vs Worse and Worse, chi=-6.72, (S_X - 1)/(S_Y - 1)=-5.41\n",
      "vs Worse and Worse 2, chi=-8.75, (S_X - 1)/(S_Y - 1)=0.62\n",
      "vs ZD-Mem2, chi=-3.97, (S_X - 1)/(S_Y - 1)=-35.48\n"
     ]
    }
   ],
   "source": [
    "for opponent in parameters.PLAYER_GROUPS[\"full\"]:\n",
    "    players = (axl.EvolvedFSM16(), opponent)\n",
    "    axl.seed(0)\n",
    "    match = axl.Match(players, turns=parameters.TURNS)\n",
    "    interactions = match.play()\n",
    "    p = get_p_from_interactions(interactions=interactions)[0]\n",
    "    x, SSError = zd.compute_least_squares(p)\n",
    "    if SSError < 0.05 and p[3] < 0.05:\n",
    "        alpha, beta = x\n",
    "        scores = match.final_score_per_turn()\n",
    "        print(f\"vs {opponent}, chi={round(-beta / alpha, 2)}, (S_X - 1)/(S_Y - 1)={round((scores[0] - 1) / (scores[1] - 1), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work shows here that not only is there a mathematical basis for suspicion: the calculation of $\\text{SSError}$ but that some high performing strategies seem to exhibit suspicious behaviour that allows them to adapt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Press, William H., and Freeman J. Dyson. \"Iterated Prisoner’s Dilemma contains strategies that dominate any evolutionary opponent.\" Proceedings of the National Academy of Sciences 109.26 (2012): 10409-10413\n",
    "\n",
    "[2] Stewart, Alexander J., and Joshua B. Plotkin. \"Extortion and cooperation in the Prisoner’s Dilemma.\" Proceedings of the National Academy of Sciences 109.26 (2012): 10134-10135.\n",
    "\n",
    "[3] Golub, Gene H., and Charles F. Van Loan. Matrix computations. Vol. 3. JHU Press, 2012.\n",
    "\n",
    "[4] The Axelrod project developers. Axelrod: v4.2.0. 2016. http://doi.org/10.5281/zenodo.1252994\n",
    "\n",
    "[5] Knight, Vincent, et al. \"An Open Framework for the Reproducible Study of the Iterated Prisoner’s Dilemma.\" Journal of Open Research Software 4.1 (2016)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:testing-zd]",
   "language": "python",
   "name": "conda-env-testing-zd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
