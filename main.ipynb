{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sym\n",
    "import axelrod as axl\n",
    "import axelrod.interaction_utils as iu\n",
    "\n",
    "import testzd as zd\n",
    "\n",
    "C, D = axl.Action.C, axl.Action.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = imp.load_source('parameters', 'data/raw/parameters.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extortionate zero determinant.\n",
    "\n",
    "In [1], given a match between 2 memory one strategies the concept of Zero Determinant strategies is introduced. It was showed that a player $p\\in\\mathbb{R}^4$ against a player $q\\in\\mathbb{R}^4$ could force a linear relationship between the scores.\n",
    "\n",
    "Assuming the following:\n",
    "\n",
    "- The utilities for player $p$: $S_x = (R, S, T, P)$ and for player $q$: $S_y = (R, T, S, P)$.\n",
    "- The normalised long run score for player $p$: $s_x$ and for player $q$: $s_y$.\n",
    "- Given $p=(p_1, p_2, p_3, p_4)$ a transformed (but equivalent) vector: $\\tilde p=(p_1 - 1, p_2 - 1, p_3, p_4)$, similarly: $\\tilde q=(1 - q_1, 1 - q_2, q_3, q_4)$\n",
    "\n",
    "The main result of [1] is that:\n",
    "\n",
    "if $\\tilde p = \\alpha S_x + \\beta S_y + \\gamma 1$ **or** if $\\tilde q = \\alpha S_x + \\beta S_y + \\gamma 1$ then:\n",
    "\n",
    "$$\n",
    "\\alpha s_x + \\beta s_y + \\gamma 1 = 0\n",
    "$$\n",
    "\n",
    "where $\\alpha, \\beta, \\gamma \\in \\mathbb{R}$\n",
    "\n",
    "As an example consider the `extort-2` strategy defined in [2]. This is given by:\n",
    "\n",
    "$$p=(8/9, 1/2, 1/3, 0)$$\n",
    "\n",
    "Let us use the `Axelrod` library [4, 5] to simulate some matches, here it is against some of the best strategies in the Axelrod library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.998"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extort2 = axl.ZDExtort2()\n",
    "players = (extort2, axl.EvolvedFSM16())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "scores = match.final_score_per_turn()\n",
    "np.round((scores[0] - 1) / (scores[1] - 1), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = (extort2, axl.EvolvedANN5())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "scores = match.final_score_per_turn()\n",
    "np.round((scores[0] - 1) / (scores[1] - 1), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.051"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = (extort2, axl.PSOGamblerMem1())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "scores = match.final_score_per_turn()\n",
    "np.round((scores[0] - 1) / (scores[1] - 1), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = (extort2, extort2)\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "scores = match.final_score_per_turn()\n",
    "(scores[0] - 1) / (scores[1] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `extort2` beats all these strategies but gets a low score against itself.\n",
    "\n",
    "In [1], in fact a specific type of Zero determinant strategy is considered, indeed if: $\\gamma=-(\\alpha + \\beta)P$ then the relationship $\\chi = S_X / S_Y$ holds where $\\chi = \\frac{-\\beta}{\\alpha}$ so that the $S_X - P$ will be at $\\chi$ times bigger than $S_Y - P$ as long as $\\chi > 1$. We can obtain a simple linear equation and an inequality that checks if a strategy is of this form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array([8 / 9, 1 / 2, 1 / 3, 0])\n",
    "zd.is_ZD(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.889, 0.5  , 0.333, 0.   ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(p, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note however that even if there is a slight measurement error then these equations will fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "approximate_p = p + 10 ** -5 * np.random.random(4)\n",
    "np.round(np.max(np.abs(p - approximate_p)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zd.is_ZD(approximate_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, this work proposes a statistical approach for recognising extortionate behaviour. This uses a least squares minimisation approach for the underlying linear algebraic problem being solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, SSError = zd.compute_least_squares(approximate_p)\n",
    "alpha, beta = x\n",
    "chi = -beta / alpha\n",
    "np.round(chi, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, exact algebraic expressions for these measure have also been obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, SSError = zd.get_least_squares(approximate_p)\n",
    "alpha, beta = x\n",
    "chi = -beta / alpha\n",
    "np.round(chi, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the large data set of collected matches we can confirm the obtained formulae:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"./data/processed/full/std/overall/main.csv\")\n",
    "    assert (np.all(np.isclose(df[\"residual\"], df[\"computed_residual\"])) and \n",
    "            np.all(np.isclose(df[\"alpha\"], df[\"computed_alpha\"])) and\n",
    "            np.all(np.isclose(df[\"beta\"], df[\"computed_beta\"])))\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in the case of an approximation of `extort2` we recover the value of $\\chi=2$ (to the third decimal place).\n",
    "\n",
    "The value that is in fact being minimised is called: $\\text{SSError}$. This in fact gives us a measure of how far from being an extortionate strategy a given strategy vector $p$ is.\n",
    "\n",
    "While all strategies are not necessarily memory one: so do not necessarily have a representation as a 4 dimensional vector. Their transition rates from all states to any action can still be measured.\n",
    "\n",
    "Let us see how this works, using the 3 strategies above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_from_interactions(interactions):\n",
    "    vectors = []\n",
    "    cooperations = iu.compute_cooperations(interactions)\n",
    "    for player, (coop_count, state_counter) in enumerate(zip(\n",
    "        cooperations, \n",
    "        iu.compute_state_to_action_distribution(interactions)\n",
    "    )):\n",
    "        p = []\n",
    "        for state in ((C, C), (C, D), (D, C), (D, D)):\n",
    "            if player == 1:\n",
    "                state = state[::-1]\n",
    "            try:\n",
    "                p.append(state_counter[(state, C)] / (state_counter[(state, C)]  + state_counter[(state, D)] ) )\n",
    "            except ZeroDivisionError:\n",
    "                p.append(coop_count / len(interactions))\n",
    "        vectors.append(p)\n",
    "    return np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = (extort2, axl.EvolvedFSM16())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "p = get_p_from_interactions(interactions=interactions)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.375, 0.544, 0.472, 0.517])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(p, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.482"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, SSError = zd.get_least_squares(p)\n",
    "np.round(SSError, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008494117647058819"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = (extort2, axl.EvolvedANN5())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "p = get_p_from_interactions(interactions=interactions)[1]\n",
    "x, SSError = zd.get_least_squares(p)\n",
    "SSError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular strategy in fact does not visit all states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(C, C): 0.0075, (D, C): 0.0025, (D, D): 0.99})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iu.compute_normalised_state_distribution(interactions=interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but the overall cooperation rate is used for the missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iu.compute_normalised_cooperation(interactions=interactions)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 0.8 , 0.01, 0.  ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players = (extort2, axl.PSOGambler2_2_2())\n",
    "axl.seed(0)\n",
    "match = axl.Match(players, turns=parameters.TURNS)\n",
    "interactions = match.play()\n",
    "p = get_p_from_interactions(interactions=interactions)[1]\n",
    "x, SSError = zd.get_least_squares(p)\n",
    "np.round(SSError, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that the `PSOGambler2_2_2` is \"less\" extortionate than `EvolvedANN5`. Note: it is certainly not an extortionate strategy as $p_4 > 0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.105, 0.002, 0.518, 0.505])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(p, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually classify all potential extortionate strategies which is Figure 1 of the paper.\n",
    "\n",
    "The paper extends this work to consider a LARGE number of strategies, and identifies if and when strategies actually exhibit extortionate behaviour.\n",
    "\n",
    "We note that the strategies that exhibit strong evolutionary fitness are ones that are able to adapt their behaviour: they do not extort strong strategies (thus cooperation evolves) but they do extort weaker ones. For example, here is a list of strategies against which `EvolvedANN5` is close to being ZD (\\\\(\\text{SS}_{\\text{error}} < 0.05\\\\)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs Adaptive, chi=-6.22, (S_X - 1)/(S_Y - 1)=-4.06\n",
      "vs AntiCycler, chi=-5.28, (S_X - 1)/(S_Y - 1)=-4.04\n",
      "vs Anti Tit For Tat, chi=-3.64, (S_X - 1)/(S_Y - 1)=-4.04\n",
      "vs Bully, chi=-4.03, (S_X - 1)/(S_Y - 1)=-4.06\n",
      "vs Calculator, chi=7.64, (S_X - 1)/(S_Y - 1)=0.48\n",
      "vs Cooperator Hunter, chi=-5.28, (S_X - 1)/(S_Y - 1)=-4.05\n",
      "vs Cycler CCCCCD, chi=16.0, (S_X - 1)/(S_Y - 1)=-4.44\n",
      "vs Cycler CCCD, chi=15.58, (S_X - 1)/(S_Y - 1)=-4.15\n",
      "vs Cycler CCD, chi=15.53, (S_X - 1)/(S_Y - 1)=-4.13\n",
      "vs Cycler DC, chi=14.74, (S_X - 1)/(S_Y - 1)=-4.18\n",
      "vs Cycler CCCDCD, chi=15.53, (S_X - 1)/(S_Y - 1)=-4.14\n",
      "vs DoubleResurrection, chi=16.0, (S_X - 1)/(S_Y - 1)=-7.53\n",
      "vs Feld: 1.0, 0.5, 200, chi=0.32, (S_X - 1)/(S_Y - 1)=0.7\n",
      "vs $\\phi$, chi=-2.9, (S_X - 1)/(S_Y - 1)=-4.04\n",
      "vs Hard Prober, chi=13.43, (S_X - 1)/(S_Y - 1)=0.0\n",
      "vs Harrington, chi=16.0, (S_X - 1)/(S_Y - 1)=0.8\n",
      "vs Hopeless, chi=15.56, (S_X - 1)/(S_Y - 1)=-4.08\n",
      "vs Knowledgeable Worse and Worse, chi=16.0, (S_X - 1)/(S_Y - 1)=4.89\n",
      "vs Negation, chi=-4.03, (S_X - 1)/(S_Y - 1)=-4.06\n",
      "vs $\\pi$, chi=-2.9, (S_X - 1)/(S_Y - 1)=-4.04\n",
      "vs Predator, chi=1.29, (S_X - 1)/(S_Y - 1)=0.58\n",
      "vs Prober, chi=11.58, (S_X - 1)/(S_Y - 1)=-0.07\n",
      "vs Prober 3, chi=11.99, (S_X - 1)/(S_Y - 1)=-0.15\n",
      "vs Prober 4, chi=2.12, (S_X - 1)/(S_Y - 1)=1.24\n",
      "vs Random Tit for Tat: 0.5, chi=14.83, (S_X - 1)/(S_Y - 1)=-4.5\n",
      "vs RichardHufford, chi=7.24, (S_X - 1)/(S_Y - 1)=4.06\n",
      "vs SelfSteem, chi=14.44, (S_X - 1)/(S_Y - 1)=-4.49\n",
      "vs Sneaky Tit For Tat, chi=-2.57, (S_X - 1)/(S_Y - 1)=-4.1\n",
      "vs Stochastic Cooperator, chi=16.0, (S_X - 1)/(S_Y - 1)=-4.42\n",
      "vs Stochastic WSLS: 0.05, chi=16.0, (S_X - 1)/(S_Y - 1)=-4.29\n",
      "vs TF1, chi=1.17, (S_X - 1)/(S_Y - 1)=0.79\n",
      "vs ThueMorse, chi=15.15, (S_X - 1)/(S_Y - 1)=-4.16\n",
      "vs ThueMorseInverse, chi=-6.05, (S_X - 1)/(S_Y - 1)=-4.09\n",
      "vs Tranquilizer, chi=3.62, (S_X - 1)/(S_Y - 1)=1.6\n",
      "vs Tricky Cooperator, chi=-4.42, (S_X - 1)/(S_Y - 1)=-4.05\n",
      "vs Tricky Defector, chi=-2.49, (S_X - 1)/(S_Y - 1)=-4.05\n",
      "vs Win-Shift Lose-Stay: D, chi=15.56, (S_X - 1)/(S_Y - 1)=-4.08\n",
      "vs Worse and Worse, chi=16.0, (S_X - 1)/(S_Y - 1)=5.35\n",
      "vs Worse and Worse 2, chi=16.0, (S_X - 1)/(S_Y - 1)=25.33\n",
      "vs ZD-Extort-2: 0.1111111111111111, 0.5, chi=8.92, (S_X - 1)/(S_Y - 1)=0.5\n",
      "vs ZD-Extort3: 0.11538461538461539, 0.3333333333333333, 1, chi=16.0, (S_X - 1)/(S_Y - 1)=0.51\n",
      "vs ZD-Extort-2 v2: 0.125, 0.5, 1, chi=8.92, (S_X - 1)/(S_Y - 1)=0.5\n",
      "vs ZD-Mem2, chi=12.3, (S_X - 1)/(S_Y - 1)=-9.79\n",
      "vs $e$, chi=-2.9, (S_X - 1)/(S_Y - 1)=-4.04\n",
      "vs Meta Hunter Aggressive: 7 players, chi=-5.09, (S_X - 1)/(S_Y - 1)=-5.9\n"
     ]
    }
   ],
   "source": [
    "for opponent in parameters.PLAYER_GROUPS[\"full\"]:\n",
    "    players = (axl.EvolvedANN5(), opponent)\n",
    "    axl.seed(0)\n",
    "    match = axl.Match(players, turns=parameters.TURNS)\n",
    "    interactions = match.play()\n",
    "    p = get_p_from_interactions(interactions=interactions)[0]\n",
    "    x, SSError = zd.compute_least_squares(p)\n",
    "    if SSError < 0.05:\n",
    "        alpha, beta = x\n",
    "        scores = match.final_score_per_turn()\n",
    "        print(f\"vs {opponent}, chi={round(-beta / alpha, 2)}, (S_X - 1)/(S_Y - 1)={round((scores[0] - 1) / (scores[1] - 1), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work shows here that not only is there a mathematical basis for suspicion: the calculation of $\\text{SSError}$ but that some high performing strategies seem to exhibit suspicious behaviour that allows them to adapt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Press, William H., and Freeman J. Dyson. \"Iterated Prisoner’s Dilemma contains strategies that dominate any evolutionary opponent.\" Proceedings of the National Academy of Sciences 109.26 (2012): 10409-10413\n",
    "\n",
    "[2] Stewart, Alexander J., and Joshua B. Plotkin. \"Extortion and cooperation in the Prisoner’s Dilemma.\" Proceedings of the National Academy of Sciences 109.26 (2012): 10134-10135.\n",
    "\n",
    "[3] Golub, Gene H., and Charles F. Van Loan. Matrix computations. Vol. 3. JHU Press, 2012.\n",
    "\n",
    "[4] The Axelrod project developers. Axelrod: v4.2.0. 2016. http://doi.org/10.5281/zenodo.1252994\n",
    "\n",
    "[5] Knight, Vincent, et al. \"An Open Framework for the Reproducible Study of the Iterated Prisoner’s Dilemma.\" Journal of Open Research Software 4.1 (2016)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:testing-zd]",
   "language": "python",
   "name": "conda-env-testing-zd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
