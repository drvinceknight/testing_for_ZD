\documentclass[a4paper]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1.5cm,
            includefoot,
            footskip=30pt]{geometry}
\usepackage{layout}
\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{biblatex}
\bibliography{main.bib}

\title{Suspicion: Recognising and evaluating the effectiveness
       of extortion in the Iterated Prisoner's Dilemma}
\author{Vincent A. Knight \and Nikoleta E. Glynatsi}
\date{\today}


\begin{document}

\maketitle

\begin{abstract}
    The Iterated Prisoner's Dilemma is a model for rational and evolutionary
    interactive behaviour. It has applications both in the study of human social
    behaviour as well as in biology.
    It is used to understand when and how a rational individual might
    accept an immediate cost to their own utility for the direct benefit of
    another.

    Much attention has been given to a class of strategies called
    Zero Determinant strategies. It has been theoretically shown that these
    strategies can ``extort'' any player.

    In this work, an approach to identify if observed strategies are playing in
    an extortionate way is described. Furthermore, experimental analysis of
    a large tournament with \input{assets/tex/number_of_full_strategies/main.tex}
    strategies is considered. In this setting
    the most highly performing strategies do not play in an extortionate way
    against each other but do against lower performing strategies.
    This suggests that whilst the theory of Zero Determinant strategies
    indicates that memory is not of fundamental importance to the evolution of
    cooperative behaviour, this is incomplete.
\end{abstract}

\section{Introduction}\label{sec:introduction}

Agent based game theoretic models have become a stalwart of the underpinning
mathematics of interactive behaviours. One of the major pieces of work
in this area is the pair of original computer tournaments run by Robert
Axelrod~\cite{Axelrod1980, Axelrod1980a}. This tournaments pitted submitted
computer strategies against each other in plays of the Iterated Prisoner's
Dilemma. A common game where agents can choose to pay a slight cost to their
immediate utility in the hope of building a reputation. This has been used in
economic and evolutionary game theory to understand the evolution of cooperative
behaviour.

Recently, a class of strategies was described in~\cite{Press2012} that can
provably extort any given opponent. In~\cite{Hilbe2013, Moran1707} some
questions have already been asked about the true effectiveness of these
strategies in an evolutionary setting. Here another question is asked: is it
possible to recognise this extortionate behaviour? A mathematical procedure for
suspicion is presented: in the same way that the continued actions of an
extortionate individual might raise suspicion.

This work makes use of the Axelrod Python library~\cite{Knight2018, Knight2016}
with a large number of Prisoner Dilemma strategies available to give an
extensive numerical example of the ideas presented.  The approach is presented
in Section~\ref{sec:delta-zd-strategies}.  All of the code and data discussed
in Section~\ref{sec:numerical-experiments} is open sourced, archived and
written according to best scientific principles~\cite{Wilson2014}. The data
archive can be found at~\cite{vincent_knight_2018_1297075}.

\section{Recognising Extortion}\label{sec:delta-zd-strategies}

In~\cite{Press2012}, given a match between 2 memory-one strategies, the concept
of Zeto-Determinant (ZD) strategies is introduced. The main result of that paper
shows that given two memory one players \(p, q\in\mathbb{R}^2\) a linear
relationship between the players' scores could be forced by one of the players.

Using the notation of~\cite{Press2012}, assuming the utilities for player \(p\)
are given by \(S_x=(R, S, T, P)\) and for player \(q\) by \(S_y=(R, T, S, P)\)
and that the stationary scores of each player is given by \(S_X\) and \(S_Y\)
respectively. The main result of~\cite{Press2012} is that if

\begin{equation}\label{eqn:linear_relationship_for_p}
    \tilde p=\alpha S_x + \beta S_y + \gamma
\end{equation}

or

\begin{equation}\label{eqn:linear_relationship_for_q}
    \tilde q=\alpha S_x + \beta S_y + \gamma
\end{equation}

where \(\tilde p = (1 - p_1, 1 - p_2, p_3, p_4)\) and
\(\tilde q = (1 - q_1, 1 - q_2, q_3, q_4)\) then:

\begin{equation}
    \alpha S_X + \beta S_Y + \gamma = 0
\end{equation}

Here, the reverse problem is considered: given a
\(p\in\mathbb{R}^4\) how does one identify \(\alpha, \beta, \gamma\) if they
exist.

To do this, equation~\ref{eqn:linear_relationship_for_p} is expressed linear
algebraically as:

\begin{equation}\label{eqn:linear_algebraic_equation_for_p}
    Mx=\tilde p  \qquad x=(\alpha, \beta, \gamma)
\end{equation}

with \(M\in\mathbb{R}^{4\times 3}\) given by:

\begin{equation}\label{eqn:definition_of_M}
    M =
    \begin{bmatrix}
        R & R & 1\\
        S & T & 1\\
        T & S & 1\\
        P & P & 1
    \end{bmatrix}
\end{equation}

Note that in general, equation (\ref{eqn:linear_algebraic_equation_for_p}) will
not necessarily have a solution. From the Rouch\'{e}-Capelli theorem if there is
a solution it is unique as \(\text{rank}(M)=3\) which is the dimension of the
variable \(x\)). Furthermore, removing a single row of \(M\) would ensure that
the corresponding matrix is invertible. This corresponds to the fact that a ZD
strategy is defined by only 3 of its values.

As an example, consider the known ZD strategy \(p=(8 / 9, 1 / 2, 1 / 3, 0)\)
from~\cite{Stewart2012} which is referred to as \texttt{Extort-2}. In the
standard case of \((R, S, T, P)=(3, 0, 5, 1)\) the inverse
of \(M_{(4)}\) (removing the last row of \(M\)) is given by:

\begin{equation}\label{eqn:inverse_of_M4}
    M_{(4)}^{-1} =
    \input{./assets/tex/inverse_of_M4/main.tex}
\end{equation}

The \(x=(\alpha, \beta, \gamma)\) that corresponds to
\(\tilde p\) is given by:

\begin{equation}\label{eqn:alpha_beta_gamma_for_extort_2}
    x = M_{(4)}^{-1}\tilde p_{(4)} =
    \input{./assets/tex/alpha_beta_gamma_for_extort_2/main.tex}
\end{equation}

Using (\ref{eqn:linear_algebraic_equation_for_p}) gives that these values lead
to the correct value for \(p_4=0\) which confirms that \(p_4\) is a ZD strategy.

This approach could in fact be used to confirm that a given strategy is acting
in a ZD manner even if it is not a memory one strategy. However, in practice, if
a closed form for \(p\) is not known, then due to measurement and/or numerical
error this would not work.

Thus, an approach based on least squares~\cite{Golub2013} is proposed. This
approach finds the best fitting \(\bar x=(\bar\alpha, \bar\beta,
\bar\gamma)\) which minimises:

\begin{equation}\label{eqn:r_squared}
    \text{SSError} = \|M x-\tilde p\|_2^2 = \sum_{i=1}^{4}\left((M\bar x)_i-\tilde p_i\right)^2
\end{equation}

Note that \(\text{SSError}\), which is the square of the Frobenius
norm~\cite{Golub2013}, becomes a measure of how close a strategy is to being a ZD
strategy.
In~\cite{Press2012} a particular type of ZD is defined, if:

\begin{equation}\label{eqn:constraint_for_extortion}
    P(\alpha + \beta)+\gamma=0
\end{equation}

then the player can ensure they get a score \(\chi\) times
larger than the opponent. This extortion coefficient is given by:

\begin{equation}\label{eqn:definition_of_chi}
    \chi=\frac{-\beta}{\alpha}
\end{equation}

Thus, if (\ref{eqn:constraint_for_extortion}) holds and \(\chi >1\) a player is
said to extort their opponent. Recalling (\ref{eqn:definition_of_M}), equation
(\ref{eqn:constraint_for_extortion}) corresponds to the last row of \(M\), thus
a ZD player \(p\) with low enough \(\text{SSError}\) extorts their opponent if
and only if \(p_4=0\) and the estimated \(\chi > 1\). Using the method of least
squares, the strategy can be considered ZD for a given threshold of
\(\text{SSError}\) and \(\chi\) can be approximated.
Figure~\ref{fig:examples_of_extortion} illustrates this for potential
strategies: for all of these we see that for the strategy to be extortionate
\(p_2\) and \(p_3\) seem to have a linear relationship: for example if \(p_1=1\)
and \(p_4=0\) then all strategies where \(p_2=p_3\) are extortionate. Suspicion
of extortion then corresponds to a threshold on \(\text{SSError}\).

\begin{figure}[!htbp]
    \begin{center}
        \includegraphics[width=\textwidth]{assets/img/examples_of_extortion/main.pdf}
        \caption{Strategies of the form:
                 \(p=(p_1, p_2, p_3, 0)\). The solid line shows the values for
                 which \(\text{SSError} < 10 ^ {-6}\). Only values for which \(\chi > 1\) are
                 displayed, strategies outside of this region can never be
                 extortionate.}
        \label{fig:examples_of_extortion}
    \end{center}
\end{figure}

By observing interactions (human or otherwise), the transition rates of given
players, their memory one representation can be approximated and this approach
can be used to recognise extortionate behaviour. The notion of comparing
theoretic and actual plays of the IPD is not novel, see for
example~\cite{Rand2013}.  Immediately it is noted that if the environment is
noisy~\cite{Wu1995} then no strategy can be considered to be extortionate as
\(p_4>0\).

In the next section, this idea will be illustrated by observing the interactions
that take place in a computer based tournament of the IPD\@.

\section{Numerical experiments}\label{sec:numerical-experiments}

In~\cite{Stewart2012} results from a tournament with
\input{./assets/tex/number_of_stewart_plotkin_strategies/main.tex} strategies,
was presented with specific consideration given to ZD strategies. This
tournament is reproduced here using the Axelrod-Python
project~\cite{Knight2016}. To obtain a good measure of the corresponding
transition rates for each strategy all matches have been run for
\input{assets/tex/number_of_turns/main.tex} turns and every match has been
repeated \input{assets/tex/number_of_repetitions/main.tex} times. All of this
interaction data is available at~\cite{vincent_knight_2018_1297075}.

Using the pair wise interactions the transition rates \(p,
q\) can be measured and the steady state probabilities inferred and compared to
the actual probabilities of each state.
This is done numerically by computing the singular eigenvector of the
matrix: \(A\) \cite{Stewart2009}:

\[
    A =
    \begin{bmatrix}
        p_1 q_1 & p_1 (1 - q_1) & (1 - p_1) q_1 & (1 -p_1) (1 - q_1) \\
        p_2 q_2 & p_2 (1 - q_2) & (1 - p_2) q_2 & (1 -p_2) (1 - q_2) \\
        p_3 q_3 & p_3 (1 - q_3) & (1 - p_3) q_3 & (1 -p_3) (1 - q_3) \\
        p_4 q_4 & p_4 (1 - q_4) & (1 - p_4) q_4 & (1 -p_4) (1 - q_4) \\
    \end{bmatrix}
\]

Figure~\ref{fig:computed_probabilities_vs_theoretic_probabilities} shows a
regression line fitted to every pairwise interaction with a reported
\(\text{SSError}\) value (pairwise interactions with missing states were
omitted). This serves to validate the approach: a part from some edge cases the
relationship is consistent.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=.8\textwidth]{./assets/img/computed_probabilities_vs_theoretic_probabilities/main.pdf}
    \caption{The
        relationship between the steady state probabilities inferred from the
        measured transitions and the actual steady state probabilities. A linear
        regression line is included validating the approach.}
    \label{fig:computed_probabilities_vs_theoretic_probabilities}
\end{figure}

Figure~\ref{fig:SSError_overall_in_stewart_plotkin} shows the \(\text{SSError}\)
values for all the strategies in the tournament, as reported
in~\cite{Stewart2012} the extortionate strategy (which has an expected
\(\text{SSError}\) approximately 0) gains a large number of wins.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=.8\textwidth]{./assets/img/SSError_overall_in_stewart_plotkin/main.pdf}
    \caption{\(\text{SSError}\) for the strategies of~\cite{Stewart2012},
    ordered both by number of wins and overall score. Cooperator and Defector
    are omitted as they do not visit all the states.}
    \label{fig:SSError_overall_in_stewart_plotkin}
\end{figure}

Here, the work of~\cite{Stewart2012} is extended by investigating a tournament
with \input{assets/tex/number_of_full_strategies/main.tex}
strategies.

The results of this analysis are shown in
Figure~\ref{fig:SSError_and_probabilities_in_full}. The top ranking strategies
by number of wins seem to be extortionate (but not against all strategies) and
it can be seen that a small sub group of strategies achieve mutual defection.
The top ranking strategies according to score all achieve mutual cooperation and
do not extort each other, however they
\textbf{do} exhibit extortionate behaviour towards a number of the lower ranking
strategies.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=.8\textwidth]{./assets/img/SSError_and_probabilities_in_full/main.pdf}
    \caption{\(\text{SSError}\) for the strategies for the full tournament. Only
    strategy interactions for which \(p_4=0\) and \(\chi>1\) are displayed.}
    \label{fig:SSError_and_probabilities_in_full}
\end{figure}

\section{Conclusion}\label{sec:conclusion}

This work defines an approach to measure whether or not a player is playing a
strategy that corresponds to an extortionate strategy as defined
in~\cite{Press2012}: a mathematical model for suspicion. Indeed
Figure~\ref{fig:examples_of_extortion} classifies all extortionate strategies.
This is done through a linear algebraic approach for approximating the solution
of a linear system. Using this, a large number of pairwise interactions is
simulated and in fact very few strategies are found to act extortionately.

The work of~\cite{Press2012}, whilst showing that a clever approach to taking
advantage of another memory one strategy exists: this is incomplete. Whilst the
elegance of this result is very attractive, just as the simplicity of the
victory of Tit For Tat in Axelrod's original tournaments was, it is incomplete.
Extortionate strategies achieve a high number of wins but they do not
achieve a high score which corresponds to the fitness landscape in an
evolutionary sense. From the large number of interactions a payoff matrix \(P\)
can be measured where \(P_{ij}\) denotes the score (using standard values of
\((R, S, T, P) = (3, 0, 5, 1)\)) of the \(i\)th strategy
against the \(j\)th strategy. Using this, the replicator equation
describes the evolution of the system based on a population density fitness
function:

\begin{equation}\label{eqn:replicator_dynamics}
    \frac{dx}{dt} = x(P-x^TP x)
\end{equation}

Equation (\ref{eqn:replicator_dynamics}) is solved numerically through an
integration technique described in~\cite{Petzold1983} and
Figure~\ref{fig:replicator_dynamics} shows the evolution of the distribution of
the system: the various strategies are ranked by scores. It is clear to see that
only the high ranking strategies survive the evolutionary process (in fact,
only \input{./assets/img/replicator_dynamics/main.tex}
have a final distribution greater than \(10 ^ {-2}\)). This confirms the
findings of~\cite{Moran1707} in which sophisticated strategies resist
evolutionary invasion of shorter memory strategies. Recalling
Figure~\ref{fig:SSError_and_probabilities_in_full} this demonstrates that:

\begin{itemize}
    \item Cooperation emerges through the evolutionary process: the high scoring
        strategies do not exhibit extortionate behaviour towards each other.
    \item Extortionate strategies do not survive the evolutionary process.
\end{itemize}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=.8\textwidth]{./assets/img/replicator_dynamics/main.pdf}
    \caption{Numerical simulation of the replicator equation
    (\ref{eqn:replicator_dynamics}): strategies are ordered by score, only the strategies with a high score survive the evolutionary process}
    \label{fig:replicator_dynamics}
\end{figure}

This work can be used to classify plays of the IPD\@: data can be collected from
actual interactions (in lab or in the field). Furthermore, this allows for a
classification method similar to the notion of fingerprinting presented
in~\cite{Ashlock2008}. Trained strategies can potentially be classified as
extortionate or not or it could be possible to even constraint the reinforcement
learning approaches that are becoming prevalent in the literature. It is worth
noting that, as described in~\cite{Harper2017}, the top ranking strategies in
the full tournament are obtained using reinforcement learning techniques, thus
suspicion of extortionate behaviour could in fact be an evolutionary trait.

\section*{Acknowledgements}

The following open source software libraries were used in this research:

\begin{itemize}
    \item The Axelrod library (IPD strategies and
        Tournaments)~\cite{Knight2016, Knight2018}.
    \item The matplotlib library (visualisation)~\cite{Droettboom2018}.
    \item The pandas, dask and numpy libraries (data
        manipulation)~\cite{Structures2010, Dask2016, Oliphant2015}.
    \item The scipy library (numerical integration of replicator
        equation)~\cite{Jones2001}.
\end{itemize}

\printbibliography

\end{document}
