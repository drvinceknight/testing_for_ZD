\documentclass[a4paper]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1.5cm,
            includefoot,
            footskip=30pt]{geometry}
\usepackage{layout}
\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{biblatex}
\usepackage{pdfpages}
\usepackage{booktabs}

\bibliography{main.bib}

\title{Suspicion: Recognising and evaluating the effectiveness
       of extortion in the Iterated Prisoner's Dilemma}
\author{Vincent A. Knight \and
        Nikoleta E. Glynatsi \and
        Jonathan Gillard \and
        Marc Harper}
\date{\today}



\begin{document}

\maketitle

\begin{abstract}
    The Iterated Prisoner's Dilemma is a model for rational and evolutionary
    interactive behaviour, having applications in biology, the study of human social
    behaviour, and many other domains.
    It is often used to understand when and how a rational individual might
    accept an immediate cost to their own utility for the direct benefit of
    another.

    Much attention has been given to a class of strategies called
    Zero Determinant strategies. It has been theoretically shown that these
    strategies can ``extort'' large classes of other strategies.

    In this work, we describd an approach to identify if observed strategies
    are playing in an extortionate manner. This corresponds to a mathematical model
    of suspicion. Furthermore, experimental analysis of a
    large tournament with
    \input{assets/tex/number_of_full_strategies/main.tex}strategies is
    considered. In this setting the most highly performing strategies do not
    play in an extortionate manner against each other but do against lower
    performing strategies.  This suggests that whilst the theory of Zero
    Determinant strategies suggests that memory is not of fundamental
    importance to the evolution of cooperative behaviour, this narrative is
    incomplete.
\end{abstract}

\section{Introduction}\label{sec:introduction}

Agent-based game-theoretic models have become a stalwart of the underpinning
mathematics of interactive behaviours. One of the major pieces of work in this
area is the pair of computer tournaments run by Robert
Axelrod~\cite{Axelrod1980, Axelrod1980a}. These tournaments pitted submitted
computer strategies against each other in plays of the Iterated Prisoner's
Dilemma, which is a common game where agents can choose to pay a slight cost to
their immediate utility in the hope of building a reputation. This has been used
in economic and evolutionary game theory to understand the evolution of
cooperative behaviour.

In~\cite{Press2012} a class of strategies that can provably extort given
opponents was described. In~\cite{Hilbe2013, Moran1707} some questions have
already been asked about the true effectiveness of these strategies in an
evolutionary setting. Here another question is asked: is it possible to
recognise this extortionate behaviour? A mathematical procedure for suspicion is
presented, reflecting the way that the continued actions of an extortionate
individual might raise suspicion.

This work makes use of the Axelrod Python library~\cite{Knight2016, Knight2018}
which contains a large number of Prisoner Dilemma strategies available for
extensive numerical examples.  The approach is presented
in Section~\ref{sec:delta-zd-strategies}.  All of the code and data discussed
in Section~\ref{sec:numerical-experiments} is open sourced, archived and
written according to best scientific principles~\cite{Wilson2014}. The data
archive can be found at~\cite{vincent_knight_2018_1297075}.

\section{Recognising Extortion}\label{sec:delta-zd-strategies}

Zero Determinant (ZD) strategies are introduced in~\cite{Press2012} in the context
of matches between two memory-one strategies.  Memory-one strategies are
represented as elements of \(\mathbb{R}^4\) mapping a state of \(\{C, D\}^2\) to
a probability of cooperating.  A match between two such strategies creates a
Markov chain with transient states \(\{C, D\}^2\).  The main result
of~\cite{Press2012} is that given two memory-one players \(p,
q\in\mathbb{R}^4\), a linear relationship between the players' scores can be
forced by one of the players.

Using the notation of~\cite{Press2012}, the utilities for player \(p\)
are given by \(S_x=(R, S, T, P)\) and for player \(q\) by \(S_y=(R, T, S, P)\)
and the stationary scores of each player are given by \(S_X\) and \(S_Y\)
respectively. The main result of~\cite{Press2012} is that if

\begin{equation}\label{eqn:linear_relationship_for_p}
    \tilde p=\alpha S_x + \beta S_y + \gamma
\end{equation}

or

\begin{equation}\label{eqn:linear_relationship_for_q}
    \tilde q=\alpha S_x + \beta S_y + \gamma
\end{equation}

where \(\tilde p = (1 - p_1, 1 - p_2, p_3, p_4)\) and
\(\tilde q = (1 - q_1, 1 - q_2, q_3, q_4)\) then:

\begin{equation}
    \alpha S_X + \beta S_Y + \gamma = 0
\end{equation}

In~\cite{Press2012} a particular type of ZD strategy is defined: extortionate
strategies. If:

\begin{equation}\label{eqn:constraint_for_extortion}
    \gamma = - P(\alpha + \beta)
\end{equation}

then the player can ensure they get a score \(\chi\) times
larger than the opponent. This extortion coefficient is given by:

\begin{equation}\label{eqn:definition_of_chi}
    \chi=\frac{-\beta}{\alpha}
\end{equation}

Thus, if (\ref{eqn:constraint_for_extortion}) holds and \(\chi >1\) a player is
said to extort their opponent.
Here, the reverse problem is considered: given a
\(p\in\mathbb{R}^4\) how does one identify \(\alpha, \beta\) if they
exist and is the strategy in fact acting in an extortionate way?

In this case constraints (\ref{eqn:linear_relationship_for_p}) and
(\ref{eqn:constraint_for_extortion}) correspond to:

\begin{align}
    \tilde p_1 & = \alpha R + \beta R - P (\alpha + \beta)
            \label{eqn:condition_for_tilde_p1}\\
    \tilde p_2 & = \alpha S + \beta T - P (\alpha + \beta)
            \label{eqn:condition_for_tilde_p2}\\
    \tilde p_3 & = \alpha T + \beta S - P (\alpha + \beta)
            \label{eqn:condition_for_tilde_p3}\\
    \tilde p_4 & = \alpha P + \beta P - P (\alpha + \beta)
            \label{eqn:condition_for_tilde_p4}
\end{align}

Equation (\ref{eqn:condition_for_tilde_p4}) ensures that \(p_4=\tilde p_4=0\).
Equations (\ref{eqn:condition_for_tilde_p1}-\ref{eqn:condition_for_tilde_p3})
can be used to eliminate \(\alpha, \beta\), giving:

\begin{equation}\label{eqn:planar_definition_of_extortion}
    \tilde p_1 = \frac{(R - P)(\tilde p_2 + \tilde p_3)}{S + T - 2P}
\end{equation}

with:

\begin{equation}\label{eqn:definition_of_chi}
    \chi = \frac{\tilde p_2 (P - T) + \tilde p_3 (S - P)}
                {\tilde p_2 (P - S) + \tilde p_3 (T - P)}
\end{equation}

Given a strategy \(p\in\mathbb{R}^{4}\) equations
(\ref{eqn:condition_for_tilde_p4}-\ref{eqn:definition_of_chi}) can be used to
check if a strategy is extortionate. The conditions correspond to:

\begin{align}
    p_1 & = \frac{(R-P)(p_2 + p_3) - R + T + S - P}{S + T - 2P}
     \label{eqn:condition_for_p1}\\
    p_4 & = 0 \label{eqn:condition_for_p4}\\
    1 & > p_2 + p_3\label{eqn:condition_for_chi}
\end{align}

The algebraic steps necessary to prove these results are available in the
supporting materials.

All extortionate strategies reside on a triangular (\ref{eqn:condition_for_chi})
plane (\ref{eqn:condition_for_p1}) in 3 dimensions (\ref{eqn:condition_for_p4}).
Using this formulation it can be seen that a necessary (but not sufficient)
condition for an extortionate strategy is that it cooperates on average less
than 50\% of the time when in a state of disagreement with the opponent
(\ref{eqn:condition_for_chi}).

As an example, consider the known extortionate strategy \(p=(8 / 9, 1 / 2, 1 /
3, 0)\) from~\cite{Stewart2012} which is referred to as \texttt{Extort-2}. In
this case, for the standard values of \((R, S, T, P) = (3, 0, 5, 1)\)
constraint (\ref{eqn:condition_for_p1}) corresponds to:

\begin{equation}
    p_1 = \frac{2(p_2 + p_3) + 1}{3}
        = \frac{2(1 / 2 + 1 / 3) + 1}{3}
        = \frac{8}{9}
\end{equation}

It is clear that in this case all constraints hold. As a counterexample,
consider the strategy that cooperates 25\% of the time: \(p=(1 /4, 1 / 4, 1 / 4,
1 / 4)\) obeys~(\ref{eqn:condition_for_chi}) but is not extortionate as:

\begin{equation}
    p_1 \ne \frac{2(p_2 + p_3) + 1}{3}
        = \frac{2(1 / 4 + 1 / 4) + 1}{3}
        = \frac{2}{3}
\end{equation}

This approach could in fact be used to confirm that a given strategy is acting
in an extortionate manner even if it is not a memory-one strategy. However, in
practice, if an exact form for \(p\) is not known but measured from observed
plays of the game then measurement and/or numerical error this might lead to an
extortionate strategy not being confirmed as such.

This problem can be written in the following linear algebraic form where
\(x=(\alpha, \beta)\)
and \(p^*=(\tilde p_1 - 1, \tilde p_2 - 1, \tilde p_3)\):

\begin{equation}\label{eqn:linear_algebraic_equation_for_p}
    Cx= p^*
\end{equation}

\(C\) corresponds to equations
(\ref{eqn:condition_for_tilde_p1}-\ref{eqn:condition_for_tilde_p3}) and is
given by:

\begin{equation}\label{eqn:definition_of_C}
    C =
    \begin{bmatrix}
        R - P & R- P \\
        S - P & T- P \\
        T - P & S- P \\
    \end{bmatrix}
\end{equation}

Note that in general, equation (\ref{eqn:linear_algebraic_equation_for_p}) will
not necessarily have a solution. From the Rouch\'{e}-Capelli theorem if there is
a solution it is unique as \(\text{rank}(C)=2\) which is the dimension of the
variable \(x\). The best fitting \(x^*\) is defined by:

\begin{equation}\label{eqn:x_star}
    x^* = \text{argmin}_{x\in\mathbb{R}^2}\|C x- p^*\|_2^2
\end{equation}

Known results~\cite{kutner2004applied, rao1973linear, wakefield2013bayesian} can
now be applied:

\begin{equation}\label{eqn:x_star_formula}
    x^* = \left(C^TC\right)^{-1}C^Tp^*
\end{equation}

The squared norm of the remaining error is referred to as
\(\text{SS}_{\text{error}}\):

\begin{equation}\label{eqn:r_squared}
    \text{SS}_{\text{error}} = \|C x^*- p^*\|_2^2
\end{equation}

This gives expressions for \(\alpha, \beta\) as \(\alpha=x^*_1\) and
\(\beta=x^*_2\) thus the conditions for a strategy to be acting extortionately
become:

\begin{equation}
    -x^*_2 < x^*_1 \label{eqn:measured_condition_for_chi}
\end{equation}

A further known result~~\cite{kutner2004applied, rao1973linear,
wakefield2013bayesian} gives an expression for
\(\text{SS}_{\text{error}}\):

\begin{equation}\label{eqn:x_SSError_formula}
    \text{SS}_{\text{error}} = {p ^ *} ^ T p ^ * -
                               p ^ * C \left(C ^ T C \right) ^ {-1} C ^ T p ^ *
                             = {p ^ *} ^ T p ^ * - p ^ * C x ^ *
\end{equation}


By observing interactions (human or otherwise), their memory-one representation
can be inferred and if
(\ref{eqn:measured_condition_for_chi}) hold
then (\ref{eqn:x_SSError_formula}) can be used to identify if a strategy is
acting extortionately.

For a measured \(p\), \(\text{SS}_{\text{error}}\) corresponds to the best
fitting \(\alpha, \beta\), which omits the value of \(p_4\) which is 0 if the
strategy is extortionate~(\ref{eqn:eqn:condition_for_p4}). Suspicion of
extortion then corresponds to a threshold on the following value \(\kappa\):

\begin{equation}\label{eqn:kappa_definition}
    \kappa = \text{SS}_{\text{error}} + p_4 ^ 2
\end{equation}

Comparing theoretic and actual plays of the
IPD is not novel, see for example~\cite{Rand2013}.

In the next section, this idea will be illustrated by observing the interactions
that take place in a large computer based tournament of the IPD\@.

\section{Numerical experiments}\label{sec:numerical-experiments}

In~\cite{Stewart2012} results from a tournament with
\input{./assets/tex/number_of_stewart_plotkin_strategies/main.tex} strategies,
was presented with specific consideration given to ZD strategies. This
tournament is reproduced here using the Axelrod-Python
library~\cite{Knight2016}. To obtain a good measure of the corresponding
transition rates for each strategy all matches have been run for
\input{assets/tex/number_of_turns/main.tex}turns and every match has been
repeated \input{assets/tex/number_of_repetitions/main.tex}times. All of this
interaction data is available at~\cite{vincent_knight_2018_1297075}. Note that
in the interest of open scientific practice, \cite{vincent_knight_2018_1297075}
also contains interaction data for noisy and probabilistic ending interactions
which are not investigated here. A good
match between the inferred Markov chain and the state distribution of the actual
interactions has been verified. Data for this is presented in the supplementary
materials.

Figure~\ref{fig:kappa_overall_in_stewart_plotkin} shows the
\(\kappa\) values for all the strategies in the tournament, as
reported in~\cite{Stewart2012} the extortionate strategy (which has an expected
\(\kappa\) approximately 0) gains a large number of wins.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=.8\textwidth]{./assets/img/kappa_overall_in_stewart_plotkin/main.pdf}
    \caption{\(\kappa\) and state probabilities for the strategies
        of~\cite{Stewart2012}, ordered both by number of wins and overall score.
        Note that Cooperator and Defector do not have measures of \(p\) in all
        states and so no \(\kappa\) can be computed.
        }
    \label{fig:kappa_overall_in_stewart_plotkin}
\end{figure}

Here, the work of~\cite{Stewart2012} is extended by investigating a tournament
with \input{assets/tex/number_of_full_strategies/main.tex}strategies. The
results of this analysis are shown in
Figure~\ref{fig:kappa_and_probabilities_in_full}. The top ranking strategies
by number of wins seem to be extortionate (but not against all strategies) and
it can be seen that a small subgroup of strategies achieve mutual defection.
All the top ranking strategies according to score achieve mutual cooperation and
do not extort each other, however they \textbf{do} exhibit extortionate
behaviour towards a number of the lower ranking strategies.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=.95\textwidth]{./assets/img/kappa_and_probabilities_in_full/main.pdf}
    \caption{\(\kappa\) for the strategies for the full
        tournament. For the \(\kappa\) plot only strategy
        interactions for which \(p_4=0\) and \(\chi>1\) are displayed. Note that
        \(P(DC)\) is not shown as it corresponds to the transpose of \(P(CD)\).}
    \label{fig:kappa_and_probabilities_in_full}
\end{figure}

A detailed look at selected strategies is given in
Table~\ref{tbl:overall_summary_results}. It can be seen that \texttt{Extort-2}
wins many matches but does not achieve a high mean score or a high mutual
cooperation rate (\(P(CC)\)).

\begin{table}[!hbtp]
    \begin{center}
    \tiny
    \input{./assets/tex/overall_summary_results/main.tex}
    \end{center}
    \caption{Summary of overall results for a selected list of strategies. The
    transition rates are computed as an average over all matches.}
    \label{tbl:overall_summary_results}
\end{table}

\section{Conclusion}\label{sec:conclusion}

This work defines an approach to measure whether or not a player is playing a
strategy that corresponds to an extortionate strategy as defined
in~\cite{Press2012}: a mathematical model for suspicion. All extortionate
strategies have been classified as lying on a triangular plane.  This rigorous
classification fails to be robust to small measurement error, thus a statistical
approach is proposed approximating the solution of a linear system. Using this,
a large number of pairwise interactions is simulated and in fact very few
strategies are found to act extortionately.

The work of~\cite{Press2012}, whilst showing that a clever approach to taking
advantage of another memory-one strategy exists: this is not the full story.
Though the elegance of this result is very attractive, just as the simplicity of
the victory of Tit For Tat in Axelrod's original tournaments was, it is
incomplete.  Extortionate strategies achieve a high number of wins but they do
not achieve a high score.
From the large number of interactions a payoff matrix \(S\)
can be measured where \(S_{ij}\) denotes the score (using standard values of
\((R, S, T, P) = (3, 0, 5, 1)\)) of the \(i\)th strategy against the \(j\)th
strategy. Using this, the replicator equation describes the evolution of the
system based on a population density fitness function:

\begin{equation}\label{eqn:replicator_dynamics}
    \frac{dx_i}{dt} = x_i(S_i-x^TS x)
\end{equation}

Equation (\ref{eqn:replicator_dynamics}) is solved numerically through an
integration technique described in~\cite{Petzold1983} and
Figure~\ref{fig:replicator_dynamics} shows the evolution of the distribution of
the system: the various strategies are ranked by scores. It is clear to see that
only the high ranking strategies survive the evolutionary process (in fact,
only \input{./assets/img/replicator_dynamics/main.tex}
have a final distribution value greater than \(10 ^ {-2}\)). This confirms the
findings of~\cite{Moran1707} in which sophisticated strategies resist
evolutionary invasion of shorter memory strategies. Recalling
Figure~\ref{fig:kappa_and_probabilities_in_full} this demonstrates that:

\begin{itemize}
    \item Cooperation emerges through the evolutionary process: the high scoring
        strategies do not exhibit extortionate behaviour towards each other.
    \item Purely extortionate strategies do not survive the evolutionary process.
\end{itemize}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=.8\textwidth]{./assets/img/replicator_dynamics/main.pdf}
    \caption{Numerical simulation of the replicator equation
    (\ref{eqn:replicator_dynamics}): strategies are ordered by score. Some
    selected strategies are highlighted with their long run population
    distribution.}
    \label{fig:replicator_dynamics}
\end{figure}

Following Axelrod's seminal work~\cite{Axelrod1980, Axelrod1980a}, it was
commonly thought that evolutionary cooperation required strategies that followed
a simple set of rules. The discovery/definition of extortionate
strategies~\cite{Press2012} seemingly showed that complex strategies could be
taken advantage of. In this manuscript it has been shown that not only is it
possible to be detect and prevent extortionate behaviour but that more complex
strategies can be evolutionary stable. The complex strategies in question were
obtained through reinforcement learning approaches~\cite{Harper2017, Moran1707}.
Thus, this work demonstrates the possibility for the evolution of cooperation
through suspicion.

\section*{Acknowledgements}

The following open source software libraries were used in this research:

\begin{itemize}
    \item The Axelrod ~\cite{Knight2016, Knight2018} library (IPD strategies and
        tournaments).
    \item The sympy library~\cite{Meurer2017} (verification of all symbolic
        calculations).
    \item The matplotlib~\cite{Droettboom2018} library (visualisation).
    \item The pandas~\cite{Structures2010}, dask~\cite{Dask2016} and
        NumPy~\cite{Oliphant2015} libraries (data manipulation).
    \item The SciPy~\cite{Jones2001} library (numerical integration of the
        replicator equation).
\end{itemize}

This work was performed using the computational facilities of the Advanced
Research Computing @ Cardiff (ARCCA) Division, Cardiff University.

\printbibliography

\newpage
\section*{Supplementary materials}

\includepdf{assets/pdf/proof_of_form_of_extortionate_strategies/main.pdf}
\includepdf{assets/pdf/comparison_of_state_probabilities/main.pdf}
\includepdf[pages={1-}]{assets/pdf/list_of_strategies/main.pdf}

\end{document}
